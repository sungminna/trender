from dotenv import load_dotenv
from langgraph.prebuilt import create_react_agent
from langgraph_supervisor import create_supervisor
from langchain.chat_models import init_chat_model
from langchain_core.messages import convert_to_messages

from .research_agent import create_research_agent
from .story_narrative_agent import create_story_narrative_agent
from .tts_agent import create_tts_agent
from utils.prompt_loader import get_prompt, prompt_loader
from utils.message_formatter import stream_and_print

load_dotenv()


def pretty_print_message(message, indent=False):
    """ë©”ì‹œì§€ ì¶œë ¥ í¬ë§·íŒ… í—¬í¼ í•¨ìˆ˜"""
    pretty_message = message.pretty_repr(html=True)
    if not indent:
        print(pretty_message)
        return

    indented = "\n".join("\t" + c for c in pretty_message.split("\n"))
    print(indented)


def pretty_print_messages(update, last_message=False):
    """ì—ì´ì „íŠ¸ ì—…ë°ì´íŠ¸ ë©”ì‹œì§€ ì¶œë ¥ í—¬í¼ í•¨ìˆ˜"""
    is_subgraph = False
    if isinstance(update, tuple):
        ns, update = update
        # ë¶€ëª¨ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ëŠ” ì¶œë ¥ì—ì„œ ì œì™¸
        if len(ns) == 0:
            return

        graph_id = ns[-1].split(":")[0]
        print(f"ğŸ”„ Update from subgraph {graph_id}:")
        print("\n")
        is_subgraph = True

    for node_name, node_update in update.items():
        update_label = f"ğŸ“‹ Update from node {node_name}:"
        if is_subgraph:
            update_label = "\t" + update_label

        print(update_label)
        print("\n")

        messages = convert_to_messages(node_update["messages"])
        if last_message:
            messages = messages[-1:]

        for m in messages:
            pretty_print_message(m, indent=is_subgraph)
        print("\n")


def create_podcast_supervisor():
    """
    í•œêµ­ì–´ íŒŸìºìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ ìŠˆí¼ë°”ì´ì € ìƒì„±
    
    Architecture:
    1. Research Agent: ì£¼ì œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ì„
    2. Story Narrative Agent: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    3. TTS Agent: ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ TTSì— ìµœì í™”
    
    Returns:
        LangGraph supervisor instance
    """
    # í•˜ìœ„ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    research_agent = create_research_agent()
    story_narrative_agent = create_story_narrative_agent()
    tts_agent = create_tts_agent()
    
    # ìŠˆí¼ë°”ì´ì € í”„ë¡¬í”„íŠ¸ ë™ì  ë¡œë“œ
    supervisor_prompt = get_prompt("super_agent")

    # ë©€í‹° ì—ì´ì „íŠ¸ ìŠˆí¼ë°”ì´ì € ìƒì„±
    supervisor = create_supervisor(
        model=init_chat_model("openai:gpt-4.1-mini"),
        agents=[research_agent, story_narrative_agent, tts_agent],
        prompt=supervisor_prompt,
        add_handoff_back_messages=True,
        output_mode="full_history",
    ).compile()
    
    return supervisor


def reload_supervisor():
    """
    í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì‹œ ìŠˆí¼ë°”ì´ì € ì¬ë¡œë“œ
    - í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ë„ í•¨ê»˜ ì¬ë¡œë“œë¨
    - ì„œë¹„ìŠ¤ ìš´ì˜ ì¤‘ í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì ìš©ì„ ìœ„í•´ ì‚¬ìš©
    """
    global supervisor
    print("Reloading Korean podcast production supervisor with updated prompt...")
    supervisor = create_podcast_supervisor()
    print("Korean podcast production supervisor reloaded successfully!")
    return supervisor


def get_available_prompts():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    return prompt_loader.list_available_prompts()


# ìŠˆí¼ë°”ì´ì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
supervisor = create_podcast_supervisor()


if __name__ == "__main__":
    """
    í…ŒìŠ¤íŠ¸ ì‹¤í–‰ë¶€
    - ìƒ˜í”Œ ìš”ì²­ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    - ì„œë¸Œê·¸ë˜í”„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
    """
    test_request = """
    ì•„ì´í°ê³¼ ê°¤ëŸ­ì‹œì˜ ê¸°ìˆ ì  ë¹„êµ
    """
    
    print("ğŸ¯ Korean Podcast Production Pipeline ì‹œì‘...")
    print("=" * 20)
    
    try:
        for chunk in supervisor.stream(
            {
                "messages": [
                    {
                        "role": "user", 
                        "content": test_request
                    }
                ]
            },
            subgraphs=True,
        ):
            pretty_print_messages(chunk, last_message=True)
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œë¡œ ì „í™˜...")
        
        result = supervisor.invoke({
            "messages": [{"role": "user", "content": test_request}]
        })
        print("âœ… ì‹¤í–‰ ì™„ë£Œ:")
        print(result)

"""Korean Story Podcast Production Supervisor Agent.
Coordinates Research â†’ Narrative â†’ TTS agents to deliver a 20-minute, TTS-ready Korean script.
Detects `[CALL_RESEARCH:` signals and loops until `[TTS_READY]` script of 6 500-8 500 chars is produced."""