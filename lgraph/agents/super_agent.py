from dotenv import load_dotenv
from langgraph.prebuilt import create_react_agent
from langgraph_supervisor import create_supervisor
from langchain.chat_models import init_chat_model
from langchain_core.messages import convert_to_messages

from .research_agent import create_research_agent
from .story_narrative_agent import create_story_narrative_agent
from .tts_agent import create_tts_agent
from utils.prompt_loader import get_prompt, prompt_loader
from utils.message_formatter import stream_and_print

load_dotenv()


def pretty_print_message(message, indent=False):
    """ë©”ì‹œì§€ë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    pretty_message = message.pretty_repr(html=True)
    if not indent:
        print(pretty_message)
        return

    indented = "\n".join("\t" + c for c in pretty_message.split("\n"))
    print(indented)


def pretty_print_messages(update, last_message=False):
    """ì—…ë°ì´íŠ¸ ë©”ì‹œì§€ë“¤ì„ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    is_subgraph = False
    if isinstance(update, tuple):
        ns, update = update
        # ë¶€ëª¨ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ëŠ” ì¶œë ¥ì—ì„œ ì œì™¸
        if len(ns) == 0:
            return

        graph_id = ns[-1].split(":")[0]
        print(f"ğŸ”„ Update from subgraph {graph_id}:")
        print("\n")
        is_subgraph = True

    for node_name, node_update in update.items():
        update_label = f"ğŸ“‹ Update from node {node_name}:"
        if is_subgraph:
            update_label = "\t" + update_label

        print(update_label)
        print("\n")

        messages = convert_to_messages(node_update["messages"])
        if last_message:
            messages = messages[-1:]

        for m in messages:
            pretty_print_message(m, indent=is_subgraph)
        print("\n")


def create_podcast_supervisor():
    """Korean Podcast Production Supervisor Agentë¥¼ ìƒì„±í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” íŒŒì¼ì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤."""
    
    # í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ ìƒì„±
    research_agent = create_research_agent()
    story_narrative_agent = create_story_narrative_agent()
    tts_agent = create_tts_agent()
    
    # ìŠˆí¼ë°”ì´ì € í”„ë¡¬í”„íŠ¸ ë¡œë“œ (íŒŒì¼ì—ì„œ ë™ì ìœ¼ë¡œ)
    supervisor_prompt = get_prompt("super_agent")

    
    # ìŠˆí¼ë°”ì´ì € ìƒì„± (ì°¸ê³  ì½”ë“œ íŒ¨í„´ ì‚¬ìš©)
    supervisor = create_supervisor(
        model=init_chat_model("openai:gpt-4.1-mini"),
        agents=[research_agent, story_narrative_agent, tts_agent],
        prompt=supervisor_prompt,
        add_handoff_back_messages=True,
        output_mode="full_history",
    ).compile()
    
    return supervisor


def reload_supervisor():
    """
    í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ Korean Podcast Production Supervisorë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤.
    ì„œë¹„ìŠ¤ ìš´ì˜ ì¤‘ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì‹œ í˜¸ì¶œí•˜ì„¸ìš”.
    í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ë„ í•¨ê»˜ ì¬ë¡œë“œë©ë‹ˆë‹¤.
    """
    global supervisor
    print("Reloading Korean podcast production supervisor with updated prompt...")
    supervisor = create_podcast_supervisor()
    print("Korean podcast production supervisor reloaded successfully!")
    return supervisor


def get_available_prompts():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return prompt_loader.list_available_prompts()


# Korean Podcast Production Supervisor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
supervisor = create_podcast_supervisor()


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ìš”ì²­
    test_request = """
    ì•„ì´í°ê³¼ ê°¤ëŸ­ì‹œì˜ ê¸°ìˆ ì  ë¹„êµ
    """
    
    print("ğŸ¯ Korean Podcast Production Pipeline ì‹œì‘...")
    print("=" * 20)
    
    # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤í–‰í•˜ë©° ì„œë¸Œê·¸ë˜í”„ ì—…ë°ì´íŠ¸ë„ í‘œì‹œ
    try:
        for chunk in supervisor.stream(
            {
                "messages": [
                    {
                        "role": "user", 
                        "content": test_request
                    }
                ]
            },
            subgraphs=True,  # ì„œë¸Œê·¸ë˜í”„ ì—…ë°ì´íŠ¸ë„ í‘œì‹œ
        ):
            pretty_print_messages(chunk, last_message=True)
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œë¡œ ì „í™˜...")
        
        # ê¸°ë³¸ ì‹¤í–‰ (ì„œë¸Œê·¸ë˜í”„ ì—†ì´)
        result = supervisor.invoke({
            "messages": [{"role": "user", "content": test_request}]
        })
        print("âœ… ì‹¤í–‰ ì™„ë£Œ:")
        print(result)

"""Korean Story Podcast Production Supervisor Agent.
Coordinates Research â†’ Narrative â†’ TTS agents to deliver a 20-minute, TTS-ready Korean script.
Detects `[CALL_RESEARCH:` signals and loops until `[TTS_READY]` script of 6 500-8 500 chars is produced."""