from dotenv import load_dotenv
from langgraph.prebuilt import create_react_agent
from langgraph_supervisor import create_supervisor
from langchain.chat_models import init_chat_model
from langchain_core.messages import convert_to_messages

from .research_agent import create_research_agent
from .story_narrative_agent import create_story_narrative_agent
from .tts_agent import create_tts_agent
from utils.prompt_loader import get_prompt, prompt_loader
from utils.message_formatter import stream_and_print
from config import settings

load_dotenv()

# Langfuse ì—°ë™ (í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ)
langfuse_handler = None
if settings.LANGFUSE_PUBLIC_KEY and settings.LANGFUSE_SECRET_KEY:
    try:
        from langfuse.langchain import CallbackHandler
        import os
        
        # Langfuse í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        os.environ["LANGFUSE_PUBLIC_KEY"] = settings.LANGFUSE_PUBLIC_KEY
        os.environ["LANGFUSE_SECRET_KEY"] = settings.LANGFUSE_SECRET_KEY
        os.environ["LANGFUSE_HOST"] = settings.LANGFUSE_HOST
        
        langfuse_handler = CallbackHandler()
        print("âœ… Langfuse íŠ¸ë ˆì´ì‹± í™œì„±í™”ë¨")
    except ImportError:
        print("âš ï¸ Langfuse íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŠ¸ë ˆì´ì‹± ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        langfuse_handler = None
else:
    print("âš ï¸ Langfuse í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŠ¸ë ˆì´ì‹± ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")


def pretty_print_message(message, indent=False):
    """ë©”ì‹œì§€ ì¶œë ¥ í¬ë§·íŒ… í—¬í¼ í•¨ìˆ˜"""
    pretty_message = message.pretty_repr(html=True)
    if not indent:
        print(pretty_message)
        return

    indented = "\n".join("\t" + c for c in pretty_message.split("\n"))
    print(indented)


def pretty_print_messages(update, last_message=False):
    """ì—ì´ì „íŠ¸ ì—…ë°ì´íŠ¸ ë©”ì‹œì§€ ì¶œë ¥ í—¬í¼ í•¨ìˆ˜"""
    is_subgraph = False
    if isinstance(update, tuple):
        ns, update = update
        # ë¶€ëª¨ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ëŠ” ì¶œë ¥ì—ì„œ ì œì™¸
        if len(ns) == 0:
            return

        graph_id = ns[-1].split(":")[0]
        print(f"ğŸ”„ Update from subgraph {graph_id}:")
        print("\n")
        is_subgraph = True

    for node_name, node_update in update.items():
        update_label = f"ğŸ“‹ Update from node {node_name}:"
        if is_subgraph:
            update_label = "\t" + update_label

        print(update_label)
        print("\n")

        messages = convert_to_messages(node_update["messages"])
        if last_message:
            messages = messages[-1:]

        for m in messages:
            pretty_print_message(m, indent=is_subgraph)
        print("\n")


def create_podcast_supervisor():
    """
    í•œêµ­ì–´ íŒŸìºìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ ìŠˆí¼ë°”ì´ì € ìƒì„±
    
    Architecture:
    1. Research Agent: ì£¼ì œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ì„
    2. Story Narrative Agent: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    3. TTS Agent: ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ TTSì— ìµœì í™”
    
    Returns:
        LangGraph supervisor instance
    """
    # í•˜ìœ„ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    research_agent = create_research_agent()
    story_narrative_agent = create_story_narrative_agent()
    tts_agent = create_tts_agent()
    
    # ìŠˆí¼ë°”ì´ì € í”„ë¡¬í”„íŠ¸ ë™ì  ë¡œë“œ
    supervisor_prompt = get_prompt("super_agent")

    # ë©€í‹° ì—ì´ì „íŠ¸ ìŠˆí¼ë°”ì´ì € ìƒì„±
    supervisor = create_supervisor(
        model=init_chat_model("openai:gpt-4.1-mini"),
        agents=[research_agent, story_narrative_agent, tts_agent],
        prompt=supervisor_prompt,
        add_handoff_back_messages=True,
        output_mode="full_history",
    ).compile()
    
    return supervisor


def run_podcast_pipeline_with_tracing(user_request: str, trace_name: str = None):
    """
    Langfuse íŠ¸ë ˆì´ì‹±ê³¼ í•¨ê»˜ íŒŸìºìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        user_request: ì‚¬ìš©ì ìš”ì²­
        trace_name: íŠ¸ë ˆì´ìŠ¤ ì´ë¦„ (ì„ íƒì‚¬í•­)
    
    Returns:
        ì‹¤í–‰ ê²°ê³¼ ì œë„ˆë ˆì´í„°
    """
    # íŠ¸ë ˆì´ì‹± ì„¤ì •
    config = {}
    if langfuse_handler:
        config["callbacks"] = [langfuse_handler]
        if trace_name:
            config["run_name"] = trace_name
    
    # ìŠˆí¼ë°”ì´ì € ì‹¤í–‰
    for chunk in supervisor.stream(
        {
            "messages": [
                {
                    "role": "user", 
                    "content": user_request
                }
            ]
        },
        config=config,
        subgraphs=True,
    ):
        yield chunk


def reload_supervisor():
    """
    í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì‹œ ìŠˆí¼ë°”ì´ì € ì¬ë¡œë“œ
    - í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ë„ í•¨ê»˜ ì¬ë¡œë“œë¨
    - ì„œë¹„ìŠ¤ ìš´ì˜ ì¤‘ í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì ìš©ì„ ìœ„í•´ ì‚¬ìš©
    """
    global supervisor
    print("Reloading Korean podcast production supervisor with updated prompt...")
    supervisor = create_podcast_supervisor()
    print("Korean podcast production supervisor reloaded successfully!")
    return supervisor


def get_available_prompts():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    return prompt_loader.list_available_prompts()


# ìŠˆí¼ë°”ì´ì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
supervisor = create_podcast_supervisor()


if __name__ == "__main__":
    """
    í…ŒìŠ¤íŠ¸ ì‹¤í–‰ë¶€
    - ìƒ˜í”Œ ìš”ì²­ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    - Langfuse íŠ¸ë ˆì´ì‹± í™œì„±í™”
    """
    test_request = """
    ì•„ì´í°ê³¼ ê°¤ëŸ­ì‹œì˜ ê¸°ìˆ ì  ë¹„êµ
    """
    
    print("ğŸ¯ Korean Podcast Production Pipeline ì‹œì‘...")
    print("=" * 20)
    
    try:
        # Langfuse íŠ¸ë ˆì´ì‹±ê³¼ í•¨ê»˜ ì‹¤í–‰
        for chunk in run_podcast_pipeline_with_tracing(
            user_request=test_request,
            trace_name="Korean Podcast Pipeline Test"
        ):
            pretty_print_messages(chunk, last_message=True)
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ê¸°ë³¸ ì‹¤í–‰ ëª¨ë“œë¡œ ì „í™˜...")
        
        result = supervisor.invoke({
            "messages": [{"role": "user", "content": test_request}]
        })
        print("âœ… ì‹¤í–‰ ì™„ë£Œ:")
        print(result)

"""Korean Story Podcast Production Supervisor Agent.
Coordinates Research â†’ Narrative â†’ TTS agents to deliver a 20-minute, TTS-ready Korean script.
Detects `[CALL_RESEARCH:` signals and loops until `[TTS_READY]` script of 6 500-8 500 chars is produced."""